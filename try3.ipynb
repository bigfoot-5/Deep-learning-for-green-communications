{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd508351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be29660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import pandas as pd\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fa5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/karthiktalluri/Downloads/Deep_learning_signals_project/predicting_complex_numbers/merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4238570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Real Part of Input</th>\n",
       "      <th>Real Part of Output</th>\n",
       "      <th>Imag Part of Input</th>\n",
       "      <th>Imag Part of Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.280737</td>\n",
       "      <td>0.770811</td>\n",
       "      <td>-0.427208</td>\n",
       "      <td>-0.250749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.385676</td>\n",
       "      <td>0.627422</td>\n",
       "      <td>-0.032750</td>\n",
       "      <td>0.244178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>-0.024803</td>\n",
       "      <td>0.321741</td>\n",
       "      <td>0.609490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.370705</td>\n",
       "      <td>-0.764049</td>\n",
       "      <td>0.281494</td>\n",
       "      <td>0.041161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.591695</td>\n",
       "      <td>-0.366071</td>\n",
       "      <td>-0.182893</td>\n",
       "      <td>-0.816991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Real Part of Input  Real Part of Output  Imag Part of Input  \\\n",
       "0           0            0.280737             0.770811           -0.427208   \n",
       "1           1            0.385676             0.627422           -0.032750   \n",
       "2           2            0.110913            -0.024803            0.321741   \n",
       "3           3           -0.370705            -0.764049            0.281494   \n",
       "4           4           -0.591695            -0.366071           -0.182893   \n",
       "\n",
       "   Imag Part of Output  \n",
       "0            -0.250749  \n",
       "1             0.244178  \n",
       "2             0.609490  \n",
       "3             0.041161  \n",
       "4            -0.816991  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d043ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"merged.csv\")\n",
    "# Drop first column of dataframe\n",
    "data = data.iloc[: , 1:]\n",
    "df = data\n",
    "#Rearranging columns of the dataset\n",
    "df = df[['Real Part of Output', 'Imag Part of Output', 'Real Part of Input', 'Imag Part of Input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34952cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Part of Output</th>\n",
       "      <th>Imag Part of Output</th>\n",
       "      <th>Real Part of Input</th>\n",
       "      <th>Imag Part of Input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770811</td>\n",
       "      <td>-0.250749</td>\n",
       "      <td>0.280737</td>\n",
       "      <td>-0.427208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627422</td>\n",
       "      <td>0.244178</td>\n",
       "      <td>0.385676</td>\n",
       "      <td>-0.032750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024803</td>\n",
       "      <td>0.609490</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.321741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.764049</td>\n",
       "      <td>0.041161</td>\n",
       "      <td>-0.370705</td>\n",
       "      <td>0.281494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.366071</td>\n",
       "      <td>-0.816991</td>\n",
       "      <td>-0.591695</td>\n",
       "      <td>-0.182893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real Part of Output  Imag Part of Output  Real Part of Input  \\\n",
       "0             0.770811            -0.250749            0.280737   \n",
       "1             0.627422             0.244178            0.385676   \n",
       "2            -0.024803             0.609490            0.110913   \n",
       "3            -0.764049             0.041161           -0.370705   \n",
       "4            -0.366071            -0.816991           -0.591695   \n",
       "\n",
       "   Imag Part of Input  \n",
       "0           -0.427208  \n",
       "1           -0.032750  \n",
       "2            0.321741  \n",
       "3            0.281494  \n",
       "4           -0.182893  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e7526c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = df[[\"Real Part of Output\", \"Imag Part of Output\"]]\n",
    "labels = df[[\"Real Part of Input\", \"Imag Part of Input\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa879893",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8, random_state= 42)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.25,train_size =0.75, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_valid = scaler.transform(x_cv)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b4413c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Part of Output</th>\n",
       "      <th>Imag Part of Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4063089</th>\n",
       "      <td>0.777741</td>\n",
       "      <td>-0.406226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177619</th>\n",
       "      <td>0.148379</td>\n",
       "      <td>-0.988459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179449</th>\n",
       "      <td>-0.427355</td>\n",
       "      <td>0.004795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695596</th>\n",
       "      <td>0.266688</td>\n",
       "      <td>-0.664563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737797</th>\n",
       "      <td>-0.874405</td>\n",
       "      <td>0.046547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Real Part of Output  Imag Part of Output\n",
       "4063089             0.777741            -0.406226\n",
       "1177619             0.148379            -0.988459\n",
       "3179449            -0.427355             0.004795\n",
       "695596              0.266688            -0.664563\n",
       "1737797            -0.874405             0.046547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d15d347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape = x_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(2))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c70a2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40e7f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "76800/76800 [==============================] - 19s 244us/step - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 2/20\n",
      "76800/76800 [==============================] - 19s 244us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 3/20\n",
      "76800/76800 [==============================] - 18s 237us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 4/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "76800/76800 [==============================] - 19s 247us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/20\n",
      "76800/76800 [==============================] - 19s 242us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 7/20\n",
      "76800/76800 [==============================] - 20s 254us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 8/20\n",
      "76800/76800 [==============================] - 19s 244us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "76800/76800 [==============================] - 19s 244us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 11/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 12/20\n",
      "76800/76800 [==============================] - 19s 243us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 13/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 14/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "76800/76800 [==============================] - 18s 239us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 16/20\n",
      "76800/76800 [==============================] - 18s 240us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 17/20\n",
      "76800/76800 [==============================] - 19s 246us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 18/20\n",
      "76800/76800 [==============================] - 20s 257us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/20\n",
      "76800/76800 [==============================] - 20s 258us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/20\n",
      "76800/76800 [==============================] - 19s 246us/step - loss: 0.0019 - val_loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x297cfcc70>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "keras_reg.fit(X_train, y_train, epochs=20,\n",
    "              validation_data=(X_valid, y_cv),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=2), lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde2d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0626bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 23s 442us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 23s 444us/step - loss: 0.0015 - val_loss: 0.0014loss:  - ETA: 1s -\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 22s 430us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 22s 426us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 22s 423us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 22s 422us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 22s 424us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 22s 423us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 22s 424us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 22s 438us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 6s 229us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.008836435280563442, n_hidden=4, n_neurons=88; total time= 4.1min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 22s 437us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 22s 429us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 22s 432us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 22s 429us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 22s 431us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 22s 438us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 22s 430us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 6s 236us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.008836435280563442, n_hidden=4, n_neurons=88; total time= 4.1min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 22s 434us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 22s 429us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 22s 432us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 22s 427us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 22s 433us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 22s 431us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 22s 432us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 22s 428us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 22s 429us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 22s 429us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 6s 233us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.008836435280563442, n_hidden=4, n_neurons=88; total time= 3.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 19s 359us/step - loss: 0.0736 - val_loss: 0.0286\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.0202 - val_loss: 0.0166\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0147 - val_loss: 0.0131\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 18s 351us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 18s 342us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 341us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "25600/25600 [==============================] - 5s 193us/step - loss: 0.0024\n",
      "[CV] END learning_rate=0.0003457015717113411, n_hidden=5, n_neurons=16; total time= 5.9min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.0344 - val_loss: 0.0165\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0141 - val_loss: 0.0124\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 18s 344us/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 18s 349us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 341us/step - loss: 0.0044 - val_loss: 0.00420s - loss: \n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 17s 342us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0039 - val_loss: 0.0038- loss: 0. - ETA: 1s - - ETA: 0s \n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 341us/step - loss: 0.0035 - val_loss: 0.0034 ETA: 0\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "25600/25600 [==============================] - 5s 191us/step - loss: 0.0028\n",
      "[CV] END learning_rate=0.0003457015717113411, n_hidden=5, n_neurons=16; total time= 5.9min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 18s 345us/step - loss: 0.0383 - val_loss: 0.0192\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 18s 345us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 18s 342us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "25600/25600 [==============================] - 5s 192us/step - loss: 0.0030\n",
      "[CV] END learning_rate=0.0003457015717113411, n_hidden=5, n_neurons=16; total time= 5.9min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0972 - val_loss: 0.0825\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 18s 345us/step - loss: 0.0760 - val_loss: 0.0717\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.0702 - val_loss: 0.0698\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0692 - val_loss: 0.0692\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0686 - val_loss: 0.0687\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 18s 346us/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 333us/step - loss: 0.0671 - val_loss: 0.0665\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0650 - val_loss: 0.0640\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0627 - val_loss: 0.0621\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0611 - val_loss: 0.0608\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 334us/step - loss: 0.0591 - val_loss: 0.0588\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 17s 336us/step - loss: 0.0577 - val_loss: 0.0568\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0545 - val_loss: 0.05270s - loss: 0.\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.0505 - val_loss: 0.0481\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0428 - val_loss: 0.0386\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 17s 337us/step - loss: 0.0362 - val_loss: 0.0342\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0319 - val_loss: 0.0297\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.0278 - val_loss: 0.0264\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 17s 333us/step - loss: 0.0254 - val_loss: 0.0246\n",
      "25600/25600 [==============================] - 5s 193us/step - loss: 0.0246\n",
      "[CV] END learning_rate=0.0004555800093655391, n_hidden=5, n_neurons=3; total time= 5.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 340us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "25600/25600 [==============================] - 5s 191us/step - loss: 0.1253\n",
      "[CV] END learning_rate=0.0004555800093655391, n_hidden=5, n_neurons=3; total time=  57.3s\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 18s 344us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 334us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 333us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "25600/25600 [==============================] - 5s 190us/step - loss: 0.1257\n",
      "[CV] END learning_rate=0.0004555800093655391, n_hidden=5, n_neurons=3; total time= 1.5min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 333us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 335us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 327us/step - loss: 0.0016 - val_loss: 0.0015 0s - loss: - ETA: 0s -\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.0015 - val_loss: 0.0015ETA: 7s - loss: 0.001 - ETA\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 327us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0014 - val_loss: 0.0014ss: 0.0 - ETA: 2\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 328us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "25600/25600 [==============================] - 5s 190us/step - loss: 0.0013\n",
      "[CV] END learning_rate=0.018047843681798154, n_hidden=4, n_neurons=14; total time= 3.4min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "25600/25600 [==============================] - 5s 185us/step - loss: 0.0013\n",
      "[CV] END learning_rate=0.018047843681798154, n_hidden=4, n_neurons=14; total time= 4.5min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 330us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 330us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 329us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 5s 187us/step - loss: 0.0012\n",
      "[CV] END learning_rate=0.018047843681798154, n_hidden=4, n_neurons=14; total time= 5.6min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0110 - val_loss: 0.0044\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 23s 444us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 23s 450us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 23s 456us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 23s 454us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 23s 446us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 23s 446us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 23s 446us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 23s 444us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 6s 239us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.0018475234625589612, n_hidden=5, n_neurons=78; total time= 7.7min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 24s 462us/step - loss: 0.0117 - val_loss: 0.0045\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 23s 450us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 23s 454us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 23s 451us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 23s 446us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 23s 445us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 23s 444us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 23s 451us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 6s 239us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.0018475234625589612, n_hidden=5, n_neurons=78; total time= 7.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 23s 454us/step - loss: 0.0105 - val_loss: 0.0040\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 23s 457us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 23s 455us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 23s 450us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 23s 455us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 23s 448us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 23s 450us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 23s 449us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 23s 451us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 23s 447us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 23s 450us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 23s 453us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 23s 455us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 23s 446us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 7s 260us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.0018475234625589612, n_hidden=5, n_neurons=78; total time= 7.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 275us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 274us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 275us/step - loss: 0.0027 - val_loss: 0.00270s\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 14s 275us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "25600/25600 [==============================] - 5s 177us/step - loss: 0.0024\n",
      "[CV] END learning_rate=0.0012120188482320452, n_hidden=1, n_neurons=67; total time= 4.7min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "25600/25600 [==============================] - 5s 176us/step - loss: 0.0024\n",
      "[CV] END learning_rate=0.0012120188482320452, n_hidden=1, n_neurons=67; total time= 4.6min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 273us/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 274us/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 274us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 277us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "25600/25600 [==============================] - 4s 174us/step - loss: 0.0025\n",
      "[CV] END learning_rate=0.0012120188482320452, n_hidden=1, n_neurons=67; total time= 4.7min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 262us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 13s 263us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 13s 264us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 13s 260us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 13s 260us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "25600/25600 [==============================] - 5s 193us/step - loss: 0.0021\n",
      "[CV] END learning_rate=0.01707714610266018, n_hidden=1, n_neurons=14; total time= 4.6min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 13s 260us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 13s 263us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 13s 264us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "25600/25600 [==============================] - 5s 176us/step - loss: 0.0026\n",
      "[CV] END learning_rate=0.01707714610266018, n_hidden=1, n_neurons=14; total time= 2.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 275us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 13s 263us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 13s 260us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 13s 261us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 273us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 13s 259us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 13s 262us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 13s 260us/step - loss: 0.0024 - val_loss: 0.0024ss: 0.\n",
      "25600/25600 [==============================] - 5s 177us/step - loss: 0.0024\n",
      "[CV] END learning_rate=0.01707714610266018, n_hidden=1, n_neurons=14; total time= 3.5min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 339us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 332us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 322us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 5s 185us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.01904966961700835, n_hidden=2, n_neurons=66; total time= 5.6min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 326us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 17s 328us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 322us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 17s 330us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "25600/25600 [==============================] - 5s 185us/step - loss: 0.0011\n",
      "[CV] END learning_rate=0.01904966961700835, n_hidden=2, n_neurons=66; total time= 5.3min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 321us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 333us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 327us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 17s 327us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 5s 184us/step - loss: 0.0012\n",
      "[CV] END learning_rate=0.01904966961700835, n_hidden=2, n_neurons=66; total time= 2.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 279us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 14s 278us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 274us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 273us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 273us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "25600/25600 [==============================] - 5s 175us/step - loss: 0.0013\n",
      "[CV] END learning_rate=0.009564573321724704, n_hidden=1, n_neurons=82; total time= 4.7min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 278us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0032 - val_loss: 0.00272s - - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.00\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0022 - val_loss: 0.0021- loss: 0.00\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 278us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 272us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 268us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 19s 378us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 15s 286us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 264us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 13s 263us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "25600/25600 [==============================] - 4s 173us/step - loss: 0.0014\n",
      "[CV] END learning_rate=0.009564573321724704, n_hidden=1, n_neurons=82; total time= 4.8min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 15s 295us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 15s 289us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 14s 277us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 15s 285us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 14s 277us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 14s 269us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 15s 286us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 15s 296us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 308us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 15s 291us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 14s 265us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 14s 270us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 14s 271us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 14s 266us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 14s 267us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 14s 272us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 18s 343us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "25600/25600 [==============================] - 5s 175us/step - loss: 0.0014\n",
      "[CV] END learning_rate=0.009564573321724704, n_hidden=1, n_neurons=82; total time= 5.0min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 321us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 17s 330us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 5s 187us/step - loss: 0.0012\n",
      "[CV] END learning_rate=0.005116171405379177, n_hidden=2, n_neurons=71; total time= 5.5min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 17s 323us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 17s 322us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0014 - val_loss: 0.0014 ETA: 0s\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 316us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0012 - val_loss: 0.0012A: 0s - loss: - ETA: 0s - loss: \n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200/51200 [==============================] - 16s 317us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 16s 315us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 5s 196us/step - loss: 0.0012\n",
      "[CV] END learning_rate=0.005116171405379177, n_hidden=2, n_neurons=71; total time= 5.5min\n",
      "Epoch 1/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "51200/51200 [==============================] - 17s 325us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 3/20\n",
      "51200/51200 [==============================] - 17s 324us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 4/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 5/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 6/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/20\n",
      "51200/51200 [==============================] - 16s 322us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "51200/51200 [==============================] - 17s 338us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/20\n",
      "51200/51200 [==============================] - 16s 320us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "51200/51200 [==============================] - 16s 319us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "51200/51200 [==============================] - 16s 318us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "51200/51200 [==============================] - 16s 321us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "25600/25600 [==============================] - 5s 193us/step - loss: 0.0012\n",
      "[CV] END learning_rate=0.005116171405379177, n_hidden=2, n_neurons=71; total time= 5.6min\n",
      "Epoch 1/20\n",
      "76800/76800 [==============================] - 31s 399us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 2/20\n",
      "76800/76800 [==============================] - 31s 400us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 3/20\n",
      "76800/76800 [==============================] - 30s 394us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 4/20\n",
      "76800/76800 [==============================] - 30s 395us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 5/20\n",
      "76800/76800 [==============================] - 30s 393us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/20\n",
      "76800/76800 [==============================] - 30s 394us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/20\n",
      "76800/76800 [==============================] - 30s 394us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "76800/76800 [==============================] - 30s 394us/step - loss: 0.0011 - val_loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x2adc8dfd0>,\n",
       "                   param_distributions={'learning_rate': [0.00875021488452691,\n",
       "                                                          0.003747679319241924,\n",
       "                                                          0.0005408759509716155,\n",
       "                                                          0.017433817013255477,\n",
       "                                                          0.0018366100135610477,\n",
       "                                                          0.013578694121716223,\n",
       "                                                          0.011286188143139364,\n",
       "                                                          0.005320741349942404,\n",
       "                                                          0.002924714763123512,\n",
       "                                                          0.027303790029096588,\n",
       "                                                          0.0...\n",
       "                                                          0.0020563693515982507,\n",
       "                                                          0.000451649719549589,\n",
       "                                                          0.006992451550047427,\n",
       "                                                          0.0036926003901528305,\n",
       "                                                          0.027425521767015935,\n",
       "                                                          0.0008549490743572535,\n",
       "                                                          0.001927866724556925,\n",
       "                                                          0.0036493276823205884,\n",
       "                                                          0.011495324399585904,\n",
       "                                                          0.0037566312607590436, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3, 4, 5],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3, 4, 5],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=20,\n",
    "                  validation_data=(X_valid, y_cv),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=2), lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db12fe53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 88, 'n_hidden': 4, 'learning_rate': 0.008836435280563442}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a94b7f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2e48d5340>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09feb8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012217008133820835"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dnn = model.predict(X_test)\n",
    "mse_dnn = mean_squared_error(y_test, y_pred_dnn)\n",
    "mse_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16df9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(\"./models\")\n",
    "model.save(\"./models/first_reg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbf6650a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2457600, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b288702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model= keras.models.Sequential()\n",
    "# model.add(keras.layers.Dense(30, activation = \"relu\", input_shape = x_train.shape[1:]))\n",
    "# for n_hidden in (100, 100, 50, 50, 50):\n",
    "#     model.add(keras.layers.Dense(n_hidden, activation=\"selu\", kernel_initializer=\"lecun_normal\")),\n",
    "# model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51328ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7517302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31144/76800 [===========>..................] - ETA: 32s - loss: 0.0635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yr/yp7st9kx4kj5v2qcvbgv3f540000gn/T/ipykernel_24556/2972254567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, y_train, epochs=20,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       validation_data=(X_valid, y_cv))\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# means \"take an average from a single value\" but keeps the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;31m# numeric formatting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seen_so_far\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                      validation_data=(X_valid, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c13162d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25600/25600 [==============================] - 7s 276us/step - loss: 0.0636\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f028851",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aaee041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END .....................max_features=2, n_estimators=3; total time=  14.5s\n",
      "[CV] END .....................max_features=2, n_estimators=3; total time=  14.3s\n",
      "[CV] END .....................max_features=2, n_estimators=3; total time=  14.2s\n",
      "[CV] END .....................max_features=2, n_estimators=3; total time=  14.4s\n",
      "[CV] END .....................max_features=2, n_estimators=3; total time=  14.5s\n",
      "[CV] END ....................max_features=2, n_estimators=10; total time=  47.7s\n",
      "[CV] END ....................max_features=2, n_estimators=10; total time=  47.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yr/yp7st9kx4kj5v2qcvbgv3f540000gn/T/ipykernel_4201/1342232519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                            return_train_score=True, verbose = 2)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "        {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d3c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor(max_features=2, n_estimators=30)\n",
    "forest_reg.fit(X_train, y_train)\n",
    "y_pred_forest = forest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cf4a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001304256320709336"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_forest = mean_squared_error(y_test, y_pred_forest)\n",
    "mse_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e23ce0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/RF_compressed.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(forest_reg, \"./models/RF_compressed.joblib\", compress=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf2bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efee25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
